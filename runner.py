# ai_rtc/runner.py

from __future__ import annotations

import os
import math
import pickle
import csv

from datetime import datetime
from typing import Dict

import numpy as np
from numpy.typing import NDArray
from sklearn.utils import check_random_state
import torch
import torch.optim as optim
from tqdm import tqdm

from config import build_arg_parser, config_from_args, MainConfig
from utils import set_seed
from data_gen import ScenarioConfig, gen_reference_data
from cl_calib import estimate_CL_for_window, WindowCalib
from policy_nets import build_policy, save_policy, load_policy
from rl_pg import RLConfig, train_rl_policy
from eval_arl import evaluate_arl1, evaluate_arl0
from benchmark import run_backend_benchmark  

from rl_pg import train_rl_policy
from rl_sac import train_sac_policy, SACConfig


def _prepare_phase1_data(cfg: MainConfig, scen: ScenarioConfig, rng) -> NDArray:
    """S0_ref (Phase I ê¸°ì¤€ ë°ì´í„°)ë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜ ìƒˆë¡œ ìƒì„±."""
    if cfg.S0_ref_path and os.path.exists(cfg.S0_ref_path):
        print(f"[Phase I] ê¸°ì¡´ S0_ref ë¡œë“œ: {cfg.S0_ref_path}")
        S0_ref = np.load(cfg.S0_ref_path)
    else:
        print("[Phase I] S0_ref ìƒˆë¡œ ìƒì„± ì¤‘...")
        S0_ref = gen_reference_data(scen, rng)
        if cfg.S0_ref_path:
            os.makedirs(os.path.dirname(cfg.S0_ref_path), exist_ok=True)
            np.save(cfg.S0_ref_path, S0_ref)
            print(f"[Phase I] S0_ref ì €ì¥: {cfg.S0_ref_path}")
    return S0_ref


def _prepare_cl_calib(
    cfg: MainConfig,
    scen: ScenarioConfig,
    S0_ref: NDArray,
) -> Dict[int, WindowCalib]:
    """ìœˆë„ìš°ë³„ CL ë³´ì • ìˆ˜í–‰ í˜¹ì€ ê¸°ì¡´ calib_map ë¡œë“œ."""
    action_set = cfg.action_set

    if cfg.calib_map_path and os.path.exists(cfg.calib_map_path) and cfg.n_boot == 0:
        print(f"[CL] n_boot=0 & ê¸°ì¡´ calib_map ì‚¬ìš©: {cfg.calib_map_path}")
        with open(cfg.calib_map_path, "rb") as f:
            calib_map = pickle.load(f)
        return calib_map

    print(f"[CL] ë¶€íŠ¸ìŠ¤íŠ¸ë©ìœ¼ë¡œ CL ì¶”ì • ì‹œì‘ (n_boot={cfg.n_boot})")
    calib_map: Dict[int, WindowCalib] = {}
    for w in tqdm(action_set, desc="[CL] windowë³„ CL ì¶”ì •"):
        calib = estimate_CL_for_window(
            S0_ref,
            d=scen.d,
            window=w,
            n_boot=cfg.n_boot,
            n_estimators=cfg.n_estimators_eval,
            seed=cfg.seed,
            backend=cfg.rf_backend,
        )
        calib_map[w] = calib

    if cfg.calib_map_path:
        os.makedirs(os.path.dirname(cfg.calib_map_path), exist_ok=True)
        with open(cfg.calib_map_path, "wb") as f:
            pickle.dump(calib_map, f)
        print(f"[CL] calib_map ì €ì¥: {cfg.calib_map_path}")

    return calib_map


def _train_policy(
    cfg: MainConfig,
    scen: ScenarioConfig,
    calib_map: Dict[int, WindowCalib],
    S0_ref: NDArray,
) -> torch.nn.Module:
    """ì •ì±… ë„¤íŠ¸ì›Œí¬ ìƒì„± + RL í•™ìŠµ (PG ë˜ëŠ” SAC)."""
    device = cfg.device
    action_set = cfg.action_set

    # -------------------------------
    # 1) ì •ì±… ë„¤íŠ¸ì›Œí¬ ìƒì„±
    # -------------------------------
    policy = build_policy(
        cfg.policy_arch,
        d=scen.d,
        num_actions=len(action_set)
    )
    policy.to(device)

    # -------------------------------
    # 2) ê¸°ì¡´ ê°€ì¤‘ì¹˜ ë¡œë“œ (ì„ íƒ)
    # -------------------------------
    if cfg.policy_in and os.path.exists(cfg.policy_in):
        print(f"[RL] ê¸°ì¡´ ì •ì±… ë¡œë“œ: {cfg.policy_in}")
        policy = load_policy(
            path=cfg.policy_in,
            d=scen.d,
            num_actions=len(action_set),
            device=device,
            arch=cfg.policy_arch,
        )

    # -------------------------------
    # 3) RL í•™ìŠµ (PG ë˜ëŠ” SAC)
    # -------------------------------
    if cfg.algo == "pg":
        # ê¸°ì¡´ PG ê²½ë¡œ
        rl_cfg = RLConfig(
            action_set=action_set,
            episodes=cfg.episodes,
            device=device,
            reward=cfg.reward,
        )
        optimizer = optim.Adam(policy.parameters(), lr=cfg.rl_lr)

        print(f"[RL] Policy Gradient í•™ìŠµ ì‹œì‘ (episodes={cfg.episodes})")

        policy = train_rl_policy(
            policy=policy,
            optimizer=optimizer,
            cfg=rl_cfg,
            scen=scen,
            calib_map=calib_map,
            S0_ref=S0_ref,
            seed=cfg.seed,
            rf_backend=cfg.rf_backend,
            n_estimators_eval=cfg.n_estimators_eval,
        )

    elif cfg.algo == "sac_discrete":
        # SAC ì´ì‚° ê²½ë¡œ
        print(f"[RL] SAC(Discrete) í•™ìŠµ ì‹œì‘ (episodes={cfg.episodes})")

        sac_cfg = SACConfig(
            action_set=tuple(cfg.action_set),
            episodes=cfg.episodes,
            device=device,
            reward=cfg.reward,
        )

        policy = train_sac_policy(
            policy=policy,
            sac_cfg=sac_cfg,
            scen=scen,
            calib_map=calib_map,
            S0_ref=S0_ref,
            seed=cfg.seed,
            rf_backend=cfg.rf_backend,
            n_estimators_eval=cfg.n_estimators_eval,
        )

    else:
        raise ValueError(f"Unknown cfg.algo '{cfg.algo}'. (ì§€ì›: 'pg', 'sac_discrete')")

    # -------------------------------
    # 4) í•™ìŠµëœ ì •ì±… ì €ì¥ (ì„ íƒ)
    # -------------------------------
    if cfg.policy_out:
        os.makedirs(os.path.dirname(cfg.policy_out), exist_ok=True)
        save_policy(policy, cfg.policy_out)
        print(f"[RL] í•™ìŠµëœ ì •ì±… ì €ì¥: {cfg.policy_out}")

    return policy


def _evaluate(
    cfg: MainConfig,
    scen: ScenarioConfig,
    calib_map: Dict[int, WindowCalib],
    S0_ref: NDArray,
    policy: torch.nn.Module,
):
    """ì‹œë‚˜ë¦¬ì˜¤ I/II ì— ëŒ€í•´ ARL1 í‰ê°€ + CSV ì €ì¥."""
    lam2_list = [0.25, 0.50, 1.00, 2.00, 3.00, 5.00, 7.00, 9.00]
    lam_list = [math.sqrt(x) for x in lam2_list]

    # ì‹¤í–‰ í´ë” ì˜ˆ: outputs/run_20251113_153012/
    base_dir = os.path.dirname(cfg.S0_ref_path)  # ì´ë¯¸ runnerì—ì„œ ì„¸íŒ…í•¨

    for scenario_name in ["I", "II"]:
        print(f"\n[í‰ê°€] Scenario {scenario_name} (action_set={cfg.action_set})")

        # --- ARL0 í‰ê°€ (ì •ìƒ ìƒíƒœ) ---
        arl0_mean, arl0_std = evaluate_arl0(
            scen_cfg=scen,
            scenario=scenario_name,
            policy=policy,
            actions=list(cfg.action_set),
            calib_map=calib_map,
            S0_ref=S0_ref,
            R=cfg.R,
            seed=cfg.seed,
            rf_backend=cfg.rf_backend,
            n_estimators_eval=cfg.n_estimators_eval,
        )

        arl_means, arl_stds = evaluate_arl1(
            scen_cfg=scen,
            lam_list=lam_list,
            scenario=scenario_name,
            policy=policy,
            actions=list(cfg.action_set),
            calib_map=calib_map,
            S0_ref=S0_ref,
            R=cfg.R,
            seed=cfg.seed,
            rf_backend=cfg.rf_backend,
            n_estimators_eval=cfg.n_estimators_eval,
        )

        # ---- CSV ì €ì¥ ----
        csv_path = os.path.join(base_dir, f"arl_results_scenario_{scenario_name}.csv")
        print(f"[ì €ì¥] {csv_path}")

        with open(csv_path, "w", encoding="utf-8", newline="") as f:
            writer = csv.writer(f)
            # ğŸ‘‡ ì»¬ëŸ¼ 2ê°œ ì¶”ê°€
            writer.writerow(["lambda2", "lambda", "arl1_mean", "arl1_std", "arl0_mean", "arl0_std"])
            for lam2, lam, mean, std in zip(lam2_list, lam_list, arl_means, arl_stds):
                writer.writerow([lam2, lam, mean, std, arl0_mean, arl0_std])

        # ---- ì½˜ì†” ì¶œë ¥ ----
        print(f"  ARL0={arl0_mean:.2f} [{arl0_std:.2f}]")
        
        for lam2, lam, mean, std in zip(lam2_list, lam_list, arl_means, arl_stds):
            print(f"  Î»Â²={lam2:.2f} Î»={lam:.4f} ARL1={mean:.2f} [{std:.2f}]")


def main():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: Phase I â†’ CL ë³´ì • â†’ RL í•™ìŠµ â†’ ARL1 í‰ê°€."""
    start_time = datetime.now()

    # 1) ì¸ì íŒŒì‹±
    parser = build_arg_parser()
    args = parser.parse_args()
    cfg = config_from_args(args)

    # ğŸ”½ğŸ”½ğŸ”½ ì—¬ê¸°ë¶€í„° ì¶”ê°€: ì¶œë ¥ í´ë” ì„¸íŒ… ğŸ”½ğŸ”½ğŸ”½
    # 1) ì‹¤í—˜ ì´ë¦„ ê²°ì •
    if cfg.exp_name is None or cfg.exp_name == "":
        exp_name = datetime.now().strftime("run_%Y%m%d_%H%M%S")
    else:
        exp_name = cfg.exp_name

    # 2) base_dir = outputs/run_...
    base_dir = os.path.join(cfg.outputs_dir, exp_name)
    os.makedirs(base_dir, exist_ok=True)
    print(f"[ì¶œë ¥] ê²°ê³¼ê°€ ì €ì¥ë  í´ë”: {base_dir}")

    # 3) S0_ref / calib_map / policy_out ì´ ë¹„ì–´ ìˆìœ¼ë©´ ê¸°ë³¸ ê²½ë¡œ ìë™ ì„¤ì •
    if not cfg.S0_ref_path:
        cfg.S0_ref_path = os.path.join(base_dir, "S0_ref.npy")
    if not cfg.calib_map_path:
        cfg.calib_map_path = os.path.join(base_dir, "calib_map.pkl")
    if not cfg.policy_out:
        cfg.policy_out = os.path.join(base_dir, "policy.pt")

    # (ì›í•˜ë©´ ARL ê²°ê³¼, ì„¤ì •ê°’ ì €ì¥ìš© ê¸°ë³¸ ê²½ë¡œë„ ë¯¸ë¦¬ ì¡ì•„ë‘˜ ìˆ˜ ìˆìŒ)
    # cfg.arl_results_path = os.path.join(base_dir, "arl_results.csv")
    # cfg.config_dump_path = os.path.join(base_dir, "config.txt")


    print(f"[ì‹œì‘] seed={cfg.seed}, device={cfg.device}, backend={cfg.rf_backend}")
    set_seed(cfg.seed)

    rng = check_random_state(cfg.seed)

    # 2) ì‹œë‚˜ë¦¬ì˜¤/ë°ì´í„° ì„¤ì • (ë…¼ë¬¸ ê¸°ë³¸ê°’)
    scen = ScenarioConfig(d=10, N0=1500, T=300, shift_time=100, sigma=1.0)
    
    # 3) Phase I ë°ì´í„° ì¤€ë¹„
    S0_ref = _prepare_phase1_data(cfg, scen, rng)

    # âœ… (ì„ íƒ) ë°±ì—”ë“œ ë²¤ì¹˜ë§ˆí¬ - ì •ìƒ ë²„ì „
    try:
        elapsed = run_backend_benchmark(
            S0_ref=S0_ref,
            d=scen.d,
            n_estimators=cfg.n_estimators_eval,
            seed=cfg.seed,
            backend=cfg.rf_backend,
        )
        print(f"[ë²¤ì¹˜ë§ˆí¬] backend='{cfg.rf_backend}' ê¸°ì¤€ 1íšŒ í†µê³„ ê³„ì‚° ì‹œê°„ â‰ˆ {elapsed:.3f} ì´ˆ")
    except Exception as e:
        print(f"[ë²¤ì¹˜ë§ˆí¬] ì‹¤íŒ¨ (ë¬´ì‹œí•´ë„ ë¨): {e}")

    # 4) CL ë³´ì •
    calib_map = _prepare_cl_calib(cfg, scen, S0_ref)

    # 5) RL ì •ì±… í•™ìŠµ
    policy = _train_policy(cfg, scen, calib_map, S0_ref)

    # 6) ARL1 í‰ê°€
    _evaluate(cfg, scen, calib_map, S0_ref, policy)

    elapsed = datetime.now() - start_time
    print(f"\n[ì™„ë£Œ] ì „ì²´ ì†Œìš” ì‹œê°„: {elapsed}")


if __name__ == "__main__":
    main()
